{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00cde4c7",
   "metadata": {},
   "source": [
    "# 4) Recursive feature elimination (RFE)\n",
    "\n",
    "This notebook shows the use of RFE to identify informative features for the classification\n",
    "\n",
    "See also the documentation of scikit-learn library (https://scikit-learn.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librairies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'regular',\n",
    "        'size'   : 18}\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12a052",
   "metadata": {},
   "source": [
    "## Generate samples to classify\n",
    "\n",
    "We first generate synthetic data with 2 classes to separate (`s0` and `s1` samples, respectively). The input dimensionality corresponds `m` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic dataset where 2 classes of s0+s1 samples of m-dimensional inputs with controlled contrast\n",
    "def gen_inputs(m,        # input dimensionality\n",
    "               s0,       # number of samples for class 0\n",
    "               s1,       # number of samples for class 1\n",
    "               scaling): # scaling factor to separate classes\n",
    "\n",
    "    # labels\n",
    "    lbl = np.zeros([s0+s1], dtype=int)\n",
    "    # inputs\n",
    "    X = np.zeros([s0+s1,m])\n",
    "\n",
    "    # create s0 and s1 samples for the 2 classes\n",
    "    for i in range(s0+s1):\n",
    "        # label\n",
    "        lbl[i] = int(i<s0)\n",
    "        # inputs are random noise plus a shift\n",
    "        for j in range(m):\n",
    "            # positive/negative shift for 1st/2nd class\n",
    "            if i<s0:\n",
    "                a = -scaling\n",
    "            else:\n",
    "                a = scaling\n",
    "            # the shift across classes linearly depends on the feature index j\n",
    "            X[i,j] = a*j/m + np.random.randn()\n",
    "            \n",
    "    return X, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ab1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate inputs and labels\n",
    "m = 50 # input dimensionality\n",
    "s0 = 100 # number of samples for class 0\n",
    "s1 = 100 # number of samples for class 1\n",
    "X, y = gen_inputs(m, s0, s1, scaling=0.5) # try 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024c6aa",
   "metadata": {},
   "source": [
    "## Parameterization of classifier\n",
    "\n",
    "We then build a pipeline for the classifier. The outer cross-validation corresponds to the train-test splitting as before.\n",
    "\n",
    "The inner crosss-validation corresponds to the optimization of the hyperparameter `C` of the classifier (logistic regression in the pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter for regularization\n",
    "Cs = [0.01,0.1,1.0,10.0,100.0]\n",
    "\n",
    "# classifier in pipeline and wrapper for RFE\n",
    "clf = Pipeline([('scl',StandardScaler()),\n",
    "                ('mlr',LogisticRegression())])\n",
    "\n",
    "# number of repetitions and storage of results\n",
    "n_rep = 10\n",
    "\n",
    "# outer cross-validation scheme\n",
    "cvs = StratifiedShuffleSplit(n_splits=n_rep, test_size=0.2)\n",
    "\n",
    "# inner cross-validation scheme\n",
    "cv_nest = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90de0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check names of parameters for pipeline (for grid search)\n",
    "print(clf.get_params())\n",
    "\n",
    "# quick fix to get coefficients from mlr estimator in pipeline\n",
    "def get_coef(clf_pipeline):\n",
    "    return clf_pipeline['mlr'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f096d7",
   "metadata": {},
   "source": [
    "## Optimization involving the tuning of hyperparameter\n",
    "\n",
    "We use `GridSearchCV` to optimize the hyperparameter, the use the best classifier pipeline on the test set and perform recursive feature elimination (RFE) to identify informative features that contribute to the correct classification. The latter gives a ranking where low ranks correspond to informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cdf8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for hyperparameter C\n",
    "gscv = GridSearchCV(clf,\n",
    "                    {'mlr__C': Cs},\n",
    "                    cv=cv_nest)\n",
    "\n",
    "acc = pd.DataFrame(columns=['type', 'log C', 'score', 'ranking'])\n",
    "\n",
    "# repeat classification\n",
    "for train_ind, test_ind in cvs.split(X, y):\n",
    "    \n",
    "    # optimize hyperparameter\n",
    "    gscv.fit(X[train_ind,:], y[train_ind])\n",
    "    clf_best = gscv.best_estimator_\n",
    "    best_C = gscv.best_params_['mlr__C']\n",
    "\n",
    "    # wrap classifier to be fitted to data to calculate the ranking\n",
    "    feature_select = RFE(clf_best, n_features_to_select=1, step=1,\n",
    "                         importance_getter=get_coef)\n",
    "    \n",
    "    # train and test classifier\n",
    "    clf_best.fit(X[train_ind,:], y[train_ind])\n",
    "    score = clf_best.score(X[test_ind,:], y[test_ind])\n",
    "    # perform RFE\n",
    "    feature_select.fit(X[train_ind,:], y[train_ind])\n",
    "    ranking = feature_select.ranking_\n",
    "    # store results\n",
    "    d = {'type': ['test'],\n",
    "         'log C': [np.log10(best_C)], \n",
    "         'score': [score],\n",
    "         'ranking': [ranking]}\n",
    "    acc = pd.concat((acc, pd.DataFrame(data=d)), ignore_index=True)\n",
    "    \n",
    "    # shuffling\n",
    "    train_ind_rand = np.random.permutation(train_ind)\n",
    "\n",
    "    clf_best.fit(X[train_ind,:], y[train_ind_rand])\n",
    "    score = clf_best.score(X[test_ind,:], y[test_ind])\n",
    "    # perform RFE\n",
    "    feature_select.fit(X[train_ind,:], y[train_ind_rand])\n",
    "    ranking = feature_select.ranking_\n",
    "    # store results\n",
    "    d = {'type': ['shuf'],\n",
    "         'log C': [np.log10(best_C)], \n",
    "         'score': [score],\n",
    "         'ranking': [ranking]}\n",
    "    acc = pd.concat((acc, pd.DataFrame(data=d)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702e677",
   "metadata": {},
   "source": [
    "Plot the results for accuracy and best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03237341",
   "metadata": {},
   "outputs": [],
   "source": [
    "chance_level = 0.5\n",
    "\n",
    "plt.figure()\n",
    "sb.violinplot(data=acc, y='score', x='type', \n",
    "              palette=['brown','orange'], scale='width')\n",
    "plt.plot([-1,2], [chance_level]*2, '--k')\n",
    "plt.yticks([0,1])\n",
    "plt.ylabel('accuracy')\n",
    "plt.tight_layout()\n",
    "plt.title('train-test accuracies')\n",
    "\n",
    "\n",
    "acc2 = acc[acc['type']=='test']\n",
    "\n",
    "plt.figure()\n",
    "sb.violinplot(data=acc2, y='log C', x='type', \n",
    "              palette=['orange'], scale='width')\n",
    "plt.tight_layout()\n",
    "plt.title('best C (log$_{10}$ scale)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0a315",
   "metadata": {},
   "source": [
    "Plot the ranking obtained from RFE.\n",
    "\n",
    "Recall that the inputs are geneterated such that \"the shift across classes linearly depends on the feature index\". This means that inputs with large index should have low (informative) ranking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d2aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(acc['ranking'].mean())\n",
    "plt.xlabel('input index')\n",
    "plt.ylabel('mean ranking across CV splits')\n",
    "plt.tight_layout()\n",
    "plt.title('ranking of informative features')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0b3dc",
   "metadata": {},
   "source": [
    "Modify the scaling for the input generation to see how the ranking changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
